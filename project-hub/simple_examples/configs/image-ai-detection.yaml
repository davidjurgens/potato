# Image Annotation with AI Detection Support
#
# This example demonstrates AI-powered object detection for image annotation.
# The AI can suggest bounding boxes which annotators can accept, modify, or reject.
#
# To run:
#   python potato/flask_server.py start project-hub/simple_examples/configs/image-ai-detection.yaml -p 8000
#
# Requirements:
#   - For YOLO: pip install ultralytics opencv-python
#   - For Ollama Vision: Install ollama and run `ollama pull llava`
#   - For OpenAI: Set OPENAI_API_KEY environment variable

annotation_task_name: "AI-Assisted Object Detection"

# Data files
data_files:
  - "data/image-ai-example.json"

# Where data is located (relative to this config)
task_dir: .

# Item display settings
item_properties:
  id_key: "id"
  text_key: "image_url"
  context_key: "context"

# Authentication (disabled for demo)
user_config:
  require_password: false

# Single annotation scheme
annotation_schemes:
  - annotation_type: image_annotation
    name: object_detection
    description: "Detect and label objects in the image. Use AI assist to get suggestions."

    # Annotation tools
    tools:
      - bbox
      - polygon

    # Object labels to detect
    labels:
      - name: "person"
        color: "#FF6B6B"
        key_value: "1"
      - name: "car"
        color: "#4ECDC4"
        key_value: "2"
      - name: "dog"
        color: "#45B7D1"
        key_value: "3"
      - name: "bicycle"
        color: "#96CEB4"
        key_value: "4"
      - name: "traffic light"
        color: "#FFEAA7"
        key_value: "5"

    # Image annotation settings
    zoom_enabled: true
    pan_enabled: true
    min_annotations: 0

    # AI Support - per-annotation-scheme settings
    ai_support:
      enabled: true
      features:
        detection: true      # "Detect" button
        pre_annotate: true   # "Auto" button - detect all objects
        hint: true           # "Hint" button - get guidance
        classification: false # "Classify" button (disabled for bbox tasks)

# Global AI configuration
ai_support:
  enabled: true

  # Choose your endpoint type:
  # - "yolo": Fast local detection (requires ultralytics)
  # - "ollama_vision": Local VLLM (requires ollama with llava)
  # - "openai_vision": Cloud GPT-4o (requires API key)
  # - "anthropic_vision": Cloud Claude (requires API key)
  endpoint_type: "ollama_vision"

  ai_config:
    # For YOLO endpoint:
    # model: "yolov8m.pt"
    # confidence_threshold: 0.5
    # iou_threshold: 0.45

    # For Ollama Vision endpoint:
    model: "llava:latest"
    base_url: "http://localhost:11434"
    max_tokens: 500
    temperature: 0.1

    # For OpenAI Vision endpoint:
    # model: "gpt-4o"
    # api_key: "${OPENAI_API_KEY}"
    # max_tokens: 1000

    # Include all AI assistants
    include:
      all: true

  # Cache configuration (optional)
  cache_config:
    disk_cache:
      enabled: false
      path: ""
    prefetch:
      warm_up_page_count: 0
      on_next: 0
      on_prev: 0

# Output settings
output_annotation_format: json
output_annotation_dir: annotations

# Debug mode for development
debug: true
