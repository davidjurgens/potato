# Ollama AI-Assisted Annotation Demo
#
# This example demonstrates all AI enhancement features using a local Ollama instance:
# - Intelligent Hints: Contextual guidance for annotators without revealing the answer
# - Keyword Highlighting: AI identifies and highlights relevant text for each label
# - Label Rationales: AI explains why each label might apply to the text
#
# Prerequisites:
#   1. Install Ollama: https://ollama.ai
#   2. Pull a model: ollama pull qwen3:0.6b
#   3. Ensure Ollama is running: ollama serve
#
# Run with: python potato/flask_server.py start project-hub/simple_examples/ollama-ai-demo/config.yaml -p 8000

annotation_task_name: "AI-Assisted Product Review Analysis"

# Server settings
port: 8000
debug: true

# Task directory (current directory)
task_dir: .
site_dir: default

# User configuration - allow anyone to annotate
user_config:
  allow_all_users: true

# Data configuration
data_files:
  - data/reviews.json

item_properties:
  id_key: id
  text_key: text

# Output directory for annotations
output_annotation_dir: annotation_output
output_annotation_format: json

# Annotation scheme - single radio button for sentiment classification
# AI buttons available: Hint, Keyword, Rationale (configured via ai_support below)
annotation_schemes:
  - annotation_type: radio
    annotation_id: 0
    name: sentiment
    description: "What is the overall sentiment of this review?"
    labels:
      - name: positive
        tooltip: "The reviewer expresses satisfaction, happiness, or approval"
        key_value: p
      - name: negative
        tooltip: "The reviewer expresses dissatisfaction, frustration, or disapproval"
        key_value: n
      - name: neutral
        tooltip: "The reviewer is factual or balanced without strong emotion"
        key_value: u
      - name: mixed
        tooltip: "The review contains both positive and negative sentiments"
        key_value: m

# AI Support Configuration - Using Ollama
ai_support:
  enabled: true
  endpoint_type: ollama

  ai_config:
    # Model to use (must be pulled first: ollama pull qwen3:0.6b)
    model: qwen3:0.6b

    # Generation parameters
    temperature: 0.7
    max_tokens: 150

    # Enable AI for all annotation schemes
    include:
      all: true

  # Caching configuration for better performance
  cache_config:
    disk_cache:
      enabled: true
      path: annotation_output/ai_cache.json

    # Pre-fetch hints for smoother UX (disabled for debugging)
    prefetch:
      warm_up_page_count: 0   # Disabled to debug errors
      on_next: 0              # Disabled to debug errors
      on_prev: 0              # Disabled to debug errors

# UI customization
ui:
  show_instance_id: true

# Annotation constraints
max_annotations_per_item: -1
max_annotations_per_user: 20
