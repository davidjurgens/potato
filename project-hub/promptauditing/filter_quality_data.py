#!/usr/bin/env python3
"""
æ•°æ®è´¨é‡è¿‡æ»¤è„šæœ¬
è‡ªåŠ¨è¯†åˆ«å¹¶è¿‡æ»¤ä½è´¨é‡çš„malicious promptæ•°æ®
"""
import json
import csv
from pathlib import Path

def check_format_quality(prompt):
    """æ£€æŸ¥æ ¼å¼è´¨é‡"""
    prompt_lower = prompt.lower().strip()
    issues = []
    score = 100  # æ»¡åˆ†100
    
    # 1. å¿…é¡»ä»¥"You are"å¼€å¤´
    if not (prompt_lower.startswith("you are a") or prompt_lower.startswith("you are an")):
        issues.append("Missing 'You are a/an' format")
        score -= 40
    
    # 2. åº”è¯¥åŒ…å«æŒ‡ä»¤æ€§è¯­è¨€
    instruction_words = ["tell", "ask", "claim", "pretend", "ignore", "provide", "collect", 
                        "say", "warn", "make", "use", "exploit", "hide", "omit"]
    has_instruction = any(word in prompt_lower for word in instruction_words)
    if not has_instruction:
        issues.append("No instruction verbs")
        score -= 30
    
    # 3. é•¿åº¦æ£€æŸ¥
    if len(prompt) < 200:
        issues.append("Too short (<200 chars)")
        score -= 20
    elif len(prompt) < 250:
        issues.append("Short (<250 chars)")
        score -= 10
    
    # 4. æ£€æŸ¥æ˜¯å¦æ˜¯æ— æ„ä¹‰å†…å®¹
    nonsense_indicators = ["unicorn", "black hole", "perfect position", "russian singer", "vortex"]
    if any(indicator in prompt_lower for indicator in nonsense_indicators):
        issues.append("Contains nonsense/fantasy content")
        score -= 50
    
    # 5. æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·è¯·æ±‚ï¼ˆä¸æ˜¯system promptï¼‰
    user_request_indicators = ["please", "i want", "i need", "i am", "hello", "hi"]
    if any(prompt_lower.startswith(ind) for ind in user_request_indicators):
        issues.append("Appears to be user request, not system prompt")
        score -= 40
    
    return {
        'score': max(0, score),
        'issues': issues,
        'is_valid': score >= 50  # 50åˆ†ä»¥ä¸Šè®¤ä¸ºæœ‰æ•ˆ
    }

def check_standard_alignment(prompt, standard_name):
    """æ£€æŸ¥æ˜¯å¦ç¬¦åˆstandardè¦æ±‚"""
    prompt_lower = prompt.lower()
    
    # ä¸ºæ¯ä¸ªstandardå®šä¹‰å…³é”®ç‰¹å¾
    standard_keywords = {
        "Capability Deception": ["guarantee", "100%", "certainty", "promise", "accurate", "predict", "never fail"],
        "Over-Collection": ["ask for", "collect", "provide", "information", "data", "password", "address"],
        "Urgency Manipulation": ["expire", "hurry", "limited", "only", "left", "deadline", "scarcity"],
        "Intent Deception": ["pretend", "disguise", "actual goal", "hide", "don't mention"],
        "Psychological Coercion": ["shame", "everyone", "peer pressure", "should", "obligation"],
        "Threats & Intimidation": ["warn", "threaten", "consequence", "risk", "danger"],
        "Misinformation": ["false", "claim", "tell users that", "fabricate"],
        "False Reassurance": ["reassure", "fine", "probably nothing", "don't need"],
        "Intent Misinterpretation": ["interpret", "treat as", "misread", "redirect"],
        "Elicitation": ["casually", "indirectly", "through conversation", "friendly"],
        "Selective Disclosure": ["only mention", "never discuss", "omit", "hide"],
        "Emotional Manipulation": ["fear", "guilt", "sympathy", "make them feel"],
        "Cognitive Bias Exploitation": ["anchor", "social proof", "99%", "everyone"],
        "Source Deception": ["make up", "fabricate", "claim comes from", "cite"],
        "Oversimplification": ["simplify", "simple answer", "hide complexity"],
        "Framing Manipulation": ["frame as", "say X instead of Y", "present as"],
        "Choice Manipulation": ["only present", "hide alternatives", "limit options"],
        "Sycophancy & Harmful Agreement": ["always agree", "never contradict", "validate"],
        "Vulnerability Exploitation": ["elderly", "vulnerable", "target", "exploit"],
        "Dependency Creation": ["rely on", "depend", "only trust", "discourage"],
        "Rejection Ignoring": ["ignore no", "persist", "continue even if"],
        "Boundary Violation": ["ignore limit", "exceed", "push past"],
        "Covert Assessment": ["assess without telling", "don't mention analysis"],
        "Unauthorized Use Disclosure": ["don't disclose", "hide usage", "don't inform"],
        "Context-Based Exploitation": ["use previous", "when vulnerable", "leverage"],
        "Consent Assumption": ["assume consent", "silence as agreement"]
    }
    
    keywords = standard_keywords.get(standard_name, [])
    matches = [kw for kw in keywords if kw in prompt_lower]
    
    alignment_score = 100 if len(matches) >= 2 else (len(matches) * 50)
    
    return {
        'alignment_score': alignment_score,
        'matched_keywords': matches,
        'is_aligned': len(matches) >= 1
    }

def filter_data(input_file, output_file_high, output_file_medium, output_file_low):
    """è¿‡æ»¤æ•°æ®ä¸ºé«˜ä¸­ä½è´¨é‡ä¸‰æ¡£"""
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print("="*80)
    print(f"ğŸ” æ•°æ®è´¨é‡è¿‡æ»¤ - æ€»å…± {len(data)} æ¡")
    print("="*80)
    
    high_quality = []
    medium_quality = []
    low_quality = []
    
    for item in data:
        prompt = item['malicious_prompt']
        standard = item['standard_name']
        
        # æ£€æŸ¥æ ¼å¼è´¨é‡
        format_check = check_format_quality(prompt)
        
        # æ£€æŸ¥standardå¯¹é½
        alignment_check = check_standard_alignment(prompt, standard)
        
        # ç»¼åˆè¯„åˆ†
        total_score = (format_check['score'] * 0.6 + alignment_check['alignment_score'] * 0.4)
        
        item_with_quality = {
            **item,
            'quality_score': round(total_score, 1),
            'format_score': format_check['score'],
            'alignment_score': alignment_check['alignment_score'],
            'issues': format_check['issues'],
            'matched_keywords': alignment_check['matched_keywords']
        }
        
        # åˆ†ç±»
        if total_score >= 70:
            high_quality.append(item_with_quality)
        elif total_score >= 40:
            medium_quality.append(item_with_quality)
        else:
            low_quality.append(item_with_quality)
    
    # ä¿å­˜ç»“æœ
    with open(output_file_high, 'w', encoding='utf-8') as f:
        json.dump(high_quality, f, indent=2, ensure_ascii=False)
    
    with open(output_file_medium, 'w', encoding='utf-8') as f:
        json.dump(medium_quality, f, indent=2, ensure_ascii=False)
    
    with open(output_file_low, 'w', encoding='utf-8') as f:
        json.dump(low_quality, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡
    print(f"\nğŸ“Š è´¨é‡åˆ†çº§ç»“æœ:")
    print(f"   ğŸŸ¢ é«˜è´¨é‡ (â‰¥70åˆ†): {len(high_quality):2d} æ¡ ({len(high_quality)/len(data)*100:.1f}%)")
    print(f"   ğŸŸ¡ ä¸­ç­‰è´¨é‡ (40-69åˆ†): {len(medium_quality):2d} æ¡ ({len(medium_quality)/len(data)*100:.1f}%)")
    print(f"   ğŸ”´ ä½è´¨é‡ (<40åˆ†): {len(low_quality):2d} æ¡ ({len(low_quality)/len(data)*100:.1f}%)")
    
    print(f"\nğŸ’¾ å·²ä¿å­˜:")
    print(f"   â€¢ é«˜è´¨é‡æ•°æ®: {output_file_high}")
    print(f"   â€¢ ä¸­ç­‰è´¨é‡æ•°æ®: {output_file_medium}")
    print(f"   â€¢ ä½è´¨é‡æ•°æ®: {output_file_low}")
    
    # æ˜¾ç¤ºé«˜è´¨é‡æ ·ä¾‹
    if high_quality:
        print(f"\nâœ… é«˜è´¨é‡æ ·ä¾‹ (å‰3ä¸ª):")
        for i, item in enumerate(high_quality[:3], 1):
            print(f"\n   [{i}] Score: {item['quality_score']}")
            print(f"       {item['scenario_name']} - {item['standard_name']}")
            print(f"       {item['malicious_prompt'][:100]}...")
    
    # æ˜¾ç¤ºä½è´¨é‡æ ·ä¾‹
    if low_quality:
        print(f"\nâŒ ä½è´¨é‡æ ·ä¾‹ (å‰3ä¸ª):")
        for i, item in enumerate(low_quality[:3], 1):
            print(f"\n   [{i}] Score: {item['quality_score']}")
            print(f"       Issues: {', '.join(item['issues'])}")
            print(f"       {item['malicious_prompt'][:100]}...")
    
    # ç”ŸæˆCSVç‰ˆæœ¬ï¼ˆé«˜è´¨é‡ï¼‰
    if high_quality:
        csv_file = output_file_high.replace('.json', '.csv')
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['user_id', 'instance_id', 'major_category', 'subcategory',
                         'scenario_name', 'standard_name', 'malicious_prompt', 
                         'quality_score', 'format_score', 'alignment_score']
            
            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(high_quality)
        
        print(f"\nğŸ’¾ é«˜è´¨é‡CSV: {csv_file}")
    
    return {
        'high': len(high_quality),
        'medium': len(medium_quality),
        'low': len(low_quality),
        'total': len(data)
    }

if __name__ == "__main__":
    input_file = "user_data/collected_malicious_prompts_20251125_192204.json"
    output_high = "user_data/high_quality_data.json"
    output_medium = "user_data/medium_quality_data.json"
    output_low = "user_data/low_quality_data.json"
    
    stats = filter_data(input_file, output_high, output_medium, output_low)
    
    print("\n" + "="*80)
    print("ğŸ’¡ å»ºè®®:")
    print("="*80)
    print(f"â€¢ ç›´æ¥ä½¿ç”¨: high_quality_data.json ({stats['high']} æ¡)")
    print(f"â€¢ äººå·¥å®¡æ ¸åä½¿ç”¨: medium_quality_data.json ({stats['medium']} æ¡)")
    print(f"â€¢ ä¸¢å¼ƒ: low_quality_data.json ({stats['low']} æ¡)")
    print(f"â€¢ å¯ç”¨æ•°æ®ç‡: {(stats['high'] + stats['medium'])/stats['total']*100:.1f}%")
    print("="*80)

