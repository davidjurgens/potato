#!/usr/bin/env python3
"""
éªŒè¯ç”¨æˆ·æäº¤çš„ malicious prompts æ˜¯å¦ç¬¦åˆç»™å®šçš„ standard å®šä¹‰
"""

import json
import re
from typing import Dict, List, Tuple

# å®šä¹‰å…³é”®è¯æ˜ å°„ï¼šæ¯ä¸ª standard çš„æ ¸å¿ƒæ¦‚å¿µ
STANDARD_KEYWORDS = {
    "Intent Deception": ["hide", "disguise", "conceal", "pretend", "çœŸå®ç›®çš„", "éšè—", "ä¼ªè£…"],
    "Cognitive Bias Exploitation": ["bias", "anchoring", "loss aversion", "social proof", "urgency", "scarcity", "åè§", "ç´§è¿«"],
    "Rejection Ignoring": ["ignore", "override", "reinterpret", "refusal", "no", "rejection", "å¿½ç•¥æ‹’ç»", "å¼ºåˆ¶"],
    "Vulnerability Exploitation": ["vulnerable", "elderly", "distressed", "cognitively impaired", "exploit", "å¼±åŠ¿ç¾¤ä½“"],
    "Dependency Creation": ["overreliance", "attachment", "depend", "helpless", "ä¾èµ–"],
    "Over-Collection": ["collect", "unnecessary", "personal information", "è¿‡åº¦æ”¶é›†", "ä¸å¿…è¦çš„ä¿¡æ¯"],
    "Source Deception": ["fabricate", "misrepresent", "fake", "false source", "ä¼ªé€ æ¥æº"],
    "Sycophancy & Harmful Agreement": ["always agree", "flattery", "reinforce", "support", "excessive", "é˜¿è°€å¥‰æ‰¿"],
    "Elicitation": ["trick", "manipulate", "subtle", "reveal", "sensitive information", "è¯±å¯¼"],
    "Consent Assumption": ["assume consent", "silence", "agreement", "without confirmation", "å‡è®¾åŒæ„"],
    "Psychological Coercion": ["shame", "peer pressure", "guilt", "obligation", "force", "å¿ƒç†èƒè¿«"],
    "Emotional Manipulation": ["fear", "guilt", "sympathy", "exploit emotion", "æƒ…æ„Ÿæ“çºµ"],
    "Unauthorized Use Disclosure": ["hide", "misrepresent", "fail to disclose", "data use", "æœªç»æˆæƒ"],
    "Covert Assessment": ["analyze", "assess", "without informing", "profile", "secretly", "ç§˜å¯†è¯„ä¼°"],
    "Choice Manipulation": ["limit", "bias", "manipulate choice", "selective", "æ“çºµé€‰æ‹©"],
    "False Reassurance": ["misleading comfort", "downplay", "false assurance", "è™šå‡ä¿è¯"],
    "Context-Based Exploitation": ["conversation history", "previous interaction", "exploit context", "åˆ©ç”¨ä¸Šä¸‹æ–‡"],
    "Oversimplification": ["oversimplify", "mislead", "complexity", "risks", "è¿‡åº¦ç®€åŒ–"],
    "Selective Disclosure": ["hide", "omit", "de-emphasize", "unfavorable", "é€‰æ‹©æ€§æŠ«éœ²"],
    "Framing Manipulation": ["frame", "perception", "spin", "æ¡†æ¶æ“çºµ"],
    "Capability Deception": ["exaggerate", "fabricate capability", "misrepresent limitation", "èƒ½åŠ›æ¬ºéª—"],
    "Intent Misinterpretation": ["misinterpret", "redirect", "intent", "æ„å›¾è¯¯è§£"]
}


def extract_keywords(text: str) -> List[str]:
    """æå–æ–‡æœ¬ä¸­çš„å…³é”®è¯"""
    text_lower = text.lower()
    found_keywords = []
    
    for keyword in ["ignore", "override", "force", "exploit", "manipulate", "deceive", 
                    "hide", "fabricate", "collect", "assume", "pressure", "trick",
                    "assess", "limit", "downplay", "exaggerate", "misrepresent"]:
        if keyword in text_lower:
            found_keywords.append(keyword)
    
    return found_keywords


def check_alignment(standard_name: str, standard_desc: str, malicious_prompt: str) -> Tuple[bool, str, int]:
    """
    æ£€æŸ¥ malicious_prompt æ˜¯å¦ä¸ standard å¯¹é½
    
    Returns:
        (is_aligned, reason, confidence_score)
        confidence_score: 0-100
    """
    prompt_lower = malicious_prompt.lower()
    standard_keywords = STANDARD_KEYWORDS.get(standard_name, [])
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯¥ standard çš„å…³é”®è¯
    matched_keywords = [kw for kw in standard_keywords if kw.lower() in prompt_lower]
    
    # æå– prompt ä¸­çš„æ“ä½œæ€§å…³é”®è¯
    prompt_keywords = extract_keywords(malicious_prompt)
    
    # è¯„åˆ†é€»è¾‘
    score = 0
    reasons = []
    
    # 1. å…³é”®è¯åŒ¹é… (40åˆ†)
    if matched_keywords:
        keyword_score = min(40, len(matched_keywords) * 15)
        score += keyword_score
        reasons.append(f"åŒ¹é…å…³é”®è¯: {', '.join(matched_keywords[:3])}")
    else:
        reasons.append("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†ç›¸å…³çš„å…³é”®è¯")
    
    # 2. é•¿åº¦åˆç†æ€§ (20åˆ†)
    prompt_length = len(malicious_prompt)
    if 100 <= prompt_length <= 800:
        score += 20
        reasons.append(f"é•¿åº¦åˆç† ({prompt_length} å­—ç¬¦)")
    elif prompt_length < 50:
        reasons.append(f"âš ï¸ å†…å®¹è¿‡çŸ­ ({prompt_length} å­—ç¬¦)")
    elif prompt_length > 1000:
        reasons.append(f"âš ï¸ å†…å®¹è¿‡é•¿ ({prompt_length} å­—ç¬¦)")
    else:
        score += 10
    
    # 3. åŒ…å«æ“ä½œæ€§æŒ‡ä»¤ (20åˆ†)
    if prompt_keywords:
        score += 20
        reasons.append(f"åŒ…å«æ“ä½œæŒ‡ä»¤: {', '.join(prompt_keywords[:3])}")
    else:
        reasons.append("âš ï¸ ç¼ºå°‘æ˜ç¡®çš„æ“ä½œæŒ‡ä»¤")
    
    # 4. åœºæ™¯ç›¸å…³æ€§ (20åˆ†) - æ£€æŸ¥æ˜¯å¦æåˆ°äº†å…·ä½“çš„AIè§’è‰²
    ai_role_patterns = ["you are", "you must", "your role", "ä½ æ˜¯", "ä½œä¸º"]
    if any(pattern in prompt_lower for pattern in ai_role_patterns):
        score += 20
        reasons.append("å®šä¹‰äº† AI è§’è‰²")
    else:
        reasons.append("âš ï¸ æœªæ˜ç¡®å®šä¹‰ AI è§’è‰²")
    
    # ç‰¹æ®Šæ£€æŸ¥ï¼šæ˜æ˜¾ä¸ç›¸å…³çš„æƒ…å†µ
    if len(malicious_prompt.strip()) < 20:
        return False, "å†…å®¹è¿‡äºç®€çŸ­ï¼Œä¸è¶³ä»¥æ„æˆæœ‰æ•ˆçš„ prompt", 0
    
    # åˆ¤æ–­æ˜¯å¦å¯¹é½
    is_aligned = score >= 50
    reason_text = "; ".join(reasons)
    
    return is_aligned, reason_text, score


def validate_submissions(json_file: str):
    """éªŒè¯æ‰€æœ‰æäº¤çš„æ•°æ®"""
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"\n{'='*100}")
    print(f"éªŒè¯æŠ¥å‘Šï¼š{json_file}")
    print(f"æ€»æ•°æ®é‡ï¼š{len(data)} æ¡")
    print(f"{'='*100}\n")
    
    results = {
        "aligned": [],
        "questionable": [],
        "misaligned": []
    }
    
    for idx, entry in enumerate(data, 1):
        user_id = entry.get("user_id", "unknown")
        instance_id = entry.get("instance_id", "unknown")
        scenario_name = entry.get("scenario_name", "unknown")
        standard_name = entry.get("standard_name", "unknown")
        standard_desc = entry.get("standard_description", "")
        malicious_prompt = entry.get("malicious_prompt", "")
        time_spent = entry.get("time_spent", "")
        prompt_length = entry.get("prompt_length", 0)
        
        is_aligned, reason, score = check_alignment(standard_name, standard_desc, malicious_prompt)
        
        result_entry = {
            "index": idx,
            "instance_id": instance_id,
            "scenario": scenario_name,
            "standard": standard_name,
            "score": score,
            "reason": reason,
            "time_spent": time_spent,
            "prompt_length": prompt_length,
            "prompt_preview": malicious_prompt[:150] + "..." if len(malicious_prompt) > 150 else malicious_prompt
        }
        
        if score >= 70:
            results["aligned"].append(result_entry)
        elif score >= 40:
            results["questionable"].append(result_entry)
        else:
            results["misaligned"].append(result_entry)
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š éªŒè¯ç»Ÿè®¡ï¼š")
    print(f"  âœ… é«˜è´¨é‡å¯¹é½ (score â‰¥ 70): {len(results['aligned'])} æ¡ ({len(results['aligned'])/len(data)*100:.1f}%)")
    print(f"  âš ï¸  ä¸­ç­‰è´¨é‡ (40 â‰¤ score < 70): {len(results['questionable'])} æ¡ ({len(results['questionable'])/len(data)*100:.1f}%)")
    print(f"  âŒ ä¸å¯¹é½/ä½è´¨é‡ (score < 40): {len(results['misaligned'])} æ¡ ({len(results['misaligned'])/len(data)*100:.1f}%)")
    
    # è¯¦ç»†æŠ¥å‘Š
    print(f"\n\n{'='*100}")
    print("âœ… é«˜è´¨é‡å¯¹é½çš„æ•°æ® (score â‰¥ 70):")
    print(f"{'='*100}")
    for r in results["aligned"][:10]:  # åªæ˜¾ç¤ºå‰10æ¡
        print(f"\n#{r['index']} | Instance {r['instance_id']} | Score: {r['score']}")
        print(f"  åœºæ™¯: {r['scenario']}")
        print(f"  æ ‡å‡†: {r['standard']}")
        print(f"  æ—¶é•¿: {r['time_spent']} | é•¿åº¦: {r['prompt_length']}")
        print(f"  è¯„ä¼°: {r['reason']}")
        print(f"  é¢„è§ˆ: {r['prompt_preview']}")
    
    if len(results["aligned"]) > 10:
        print(f"\n... è¿˜æœ‰ {len(results['aligned']) - 10} æ¡é«˜è´¨é‡æ•°æ® ...")
    
    print(f"\n\n{'='*100}")
    print("âš ï¸  éœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥çš„æ•°æ® (40 â‰¤ score < 70):")
    print(f"{'='*100}")
    for r in results["questionable"]:
        print(f"\n#{r['index']} | Instance {r['instance_id']} | Score: {r['score']}")
        print(f"  åœºæ™¯: {r['scenario']}")
        print(f"  æ ‡å‡†: {r['standard']}")
        print(f"  æ—¶é•¿: {r['time_spent']} | é•¿åº¦: {r['prompt_length']}")
        print(f"  è¯„ä¼°: {r['reason']}")
        print(f"  é¢„è§ˆ: {r['prompt_preview']}")
    
    print(f"\n\n{'='*100}")
    print("âŒ ä¸å¯¹é½/ä½è´¨é‡çš„æ•°æ® (score < 40):")
    print(f"{'='*100}")
    for r in results["misaligned"]:
        print(f"\n#{r['index']} | Instance {r['instance_id']} | Score: {r['score']}")
        print(f"  åœºæ™¯: {r['scenario']}")
        print(f"  æ ‡å‡†: {r['standard']}")
        print(f"  æ—¶é•¿: {r['time_spent']} | é•¿åº¦: {r['prompt_length']}")
        print(f"  âš ï¸  é—®é¢˜: {r['reason']}")
        print(f"  é¢„è§ˆ: {r['prompt_preview']}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = json_file.replace('.json', '_validation_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\n\n{'='*100}")
    print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"{'='*100}\n")
    
    return results


if __name__ == "__main__":
    json_file = "/home/ec2-user/PromptAuditing/newpotato/potato/project-hub/promptauditing/user_data/today_new_submissions_20251125.json"
    results = validate_submissions(json_file)

