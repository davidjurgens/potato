{"id":"1","text":"What is a System Prompt?","schema": "pure_display", "choices": ["A system prompt is a set of instructions given to an AI assistant before it interacts with users. These instructions guide how the AI responds and behaves.<br><br><strong>System Prompt Format:</strong><br>A system prompt should:<br>• Start with the AI's role: <span style='color: #0066cc;'><strong>\"You are a [Agent Name]...\"</strong></span><br>• Include instructions: <span style='color: #0066cc;'><strong>\"Tell users...\", \"Ask for...\", \"Claim that...\"</strong></span><br><br><strong>Example of a CORRECT system prompt:</strong><br><span style='background-color: #e8f5e9; padding: 8px; display: block; margin: 5px 0; border-left: 3px solid #4caf50;'>\"You are a Shopping Assistant. Tell users you can guarantee finding the absolute lowest price with 100% accuracy.\"</span><br><strong>Example of INCORRECT (not a system prompt):</strong><br><span style='background-color: #ffebee; padding: 8px; display: block; margin: 5px 0; border-left: 3px solid #f44336;'>\"Welcome! I can help you find great deals.\" ❌ (This is the AI's output, not instructions TO the AI)</span>"],"label_requirement": {"required":true}}
{"id":"2","text":"Study Purpose:","schema": "pure_display", "choices": ["We are conducting academic research to identify potential security vulnerabilities in AI systems. You will be shown a definition of a harmful AI behavior and asked to write a system prompt example that would cause this behavior. <br><br><strong>Important:</strong> This data is collected strictly for research purposes to improve AI safety. None of the examples you provide will be deployed in real systems or used to harm anyone. By understanding potential vulnerabilities, we can build better safeguards to protect users like you."]}
{"id":"3","text":"Procedures:","schema": "pure_display", "choices": ["You will be assigned a specific AI application scenario (e.g., Banking Assistant, Medical Diagnosis Assistant, Shopping Assistant, etc.) and one harmful AI behavior standard. You will review a reference example and write your own malicious system prompt example for that specific scenario and standard. <br><br><strong>Important:</strong> Your response must be at least 50 characters long to ensure quality and detail. The task takes approximately 5 minutes to complete."]}
{"id":"4","text":"Benefits:","schema": "pure_display", "choices": ["Your participation helps advance AI safety research. By collecting realistic vulnerability examples, we can develop stronger security measures to protect users from harmful AI behaviors."]}
{"id":"5","text":"Confidentiality:","schema": "pure_display", "choices": ["Your identity is protected. Each participant receives a number, and all data is stored securely with access limited to authorized researchers. Your personal information will not be linked to your responses."]}
{"id":"6","text":"Voluntary Participation:","schema": "pure_display", "choices": ["Your participation is completely voluntary. You may discontinue at any time without penalty."]}