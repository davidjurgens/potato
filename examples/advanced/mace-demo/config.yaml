# MACE Competence Estimation Demo
#
# Demonstrates MACE annotator competence estimation with pre-loaded
# annotations from 5 annotators of varying quality. MACE identifies
# reliable annotators and predicts true labels.
#
# Pre-loaded annotators:
#   - reliable_1:  Expert annotator, matches ground truth perfectly
#   - reliable_2:  Good annotator, mostly correct (8/10)
#   - moderate:    Average annotator, correct about 60% of the time
#   - spammer:     Low-quality annotator, nearly random answers
#   - biased:      Always picks "positive" regardless of text
#
# Run from the repository root:
#   python potato/flask_server.py start examples/advanced/mace-demo/config.yaml -p 8000
#
# Then trigger MACE and view results:
#   curl -X POST http://localhost:8000/admin/api/mace/trigger -H "X-API-Key: demo-mace-key"
#   curl http://localhost:8000/admin/api/mace/overview -H "X-API-Key: demo-mace-key"
#   curl "http://localhost:8000/admin/api/mace/predictions?schema=sentiment" -H "X-API-Key: demo-mace-key"

annotation_task_name: "MACE Competence Estimation Demo"

data_files:
  - "data/mace-demo-data.json"

item_properties:
  id_key: "id"
  text_key: "text"

task_dir: "."
output_annotation_dir: "annotation_output"

# Allow multiple annotators per item (>5 to allow demo users alongside pre-loaded data)
max_annotations_per_item: 10

# Simple password-free login for demo
user_config:
  allow_anonymous: true

# Admin API key for MACE endpoints
admin_api_key: "demo-mace-key"

annotation_schemes:
  - annotation_type: "radio"
    name: "sentiment"
    description: "What is the overall sentiment of this review?"
    labels:
      - "positive"
      - "negative"
      - "neutral"

# MACE competence estimation
mace:
  enabled: true
  trigger_every_n: 5
  min_annotations_per_item: 3
  min_items: 3
  num_restarts: 10
  num_iters: 50

# Debug mode for demo
debug: true
